{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('\\n\\nAs of June 2020, there are eight planets in our Solar System: Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, and Neptune.',\n",
       " 'As of now, there are eight recognized planets in our solar system. They are Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, and Neptune. However, there is ongoing debate among astronomers regarding the classification of Pluto as a planet, as it was reclassified as a dwarf planet in 2006 by the International Astronomical Union (IAU).')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.0 LLMs and Chat Models\n",
    "\n",
    "from langchain.llms.openai import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import os\n",
    "# .env 파일 쓰려면 dotenv 사용하기\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "openai_api_key = os.environ.get('OPENAI_API_KEY')\n",
    "\n",
    "llm = OpenAI(openai_api_key=openai_api_key)\n",
    "chat = ChatOpenAI(openai_api_key=openai_api_key, temperature=0.1)\n",
    "a = llm.predict(\"How many planets are there?\")\n",
    "b = chat.predict(\"How many planets are there?\")\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Ciao! Il mio nome è Paolo. La distanza tra il Messico e la Thailandia è di circa 18.000 chilometri.')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.1 Predict Messages\n",
    "\n",
    "from langchain.schema import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\n",
    "        content=\"You are a geography expert. And you only reply in Italian.\"\n",
    "    ),\n",
    "    AIMessage(content=\"Ciao, mi chiamo Paolo!\"),\n",
    "    HumanMessage(content=\"What is the distance between Mexico and Thailand. Also, what is your name?\")\n",
    "]\n",
    "\n",
    "chat.predict_messages(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The distance between Mexico and Thailand is approximately 16,000 kilometers (9,942 miles).'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.2 Prompt Templates\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "import os\n",
    "# .env 파일 쓰려면 dotenv 사용하기\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "openai_api_key = os.environ.get('OPENAI_API_KEY')\n",
    "\n",
    "chat = ChatOpenAI(openai_api_key=openai_api_key, temperature=0.1)\n",
    "\n",
    "template = PromptTemplate.from_template(\"What is the distance between {country_a} and {country_b}\")\n",
    "\n",
    "prompt = template.format(country_a=\"Mexcio\", country_b=\"Thailand\")\n",
    "\n",
    "chat.predict(prompt)\n",
    "\n",
    "template_message = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a geography expert. And you only reply in {language}.\"),\n",
    "    (\"ai\", \"Ciao, mi chiamo {name}!\"),\n",
    "    (\"human\", \"What is the distance between {country_a} and {country_b}. Also, what is your name?\")\n",
    "])\n",
    "\n",
    "prompt = template_message.format_messages(\n",
    "    language=\"Greek\",\n",
    "    name=\"Socrates\",\n",
    "    country_a = \"Mexico\",\n",
    "    country_b = \"korea\",\n",
    ")\n",
    "\n",
    "chat.predict_messages(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pikachu', 'charizard', 'bulbasaur', 'squirtle', 'jigglypuff']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.3 OutputParser and LCEL\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "openai_api_key = os.environ.get('OPENAI_API_KEY')\n",
    "\n",
    "chat = ChatOpenAI(openai_api_key=openai_api_key, temperature=0.1)\n",
    "\n",
    "class CommaOutputParser(BaseOutputParser):\n",
    "\n",
    "    def parse(self, text):\n",
    "        items = text.strip().split(\",\")\n",
    "        return list(map(str.strip, items))\n",
    "    \n",
    "\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a list generating machine. Everything you are asked will be answered with a comma separated list of max {max_items} in lowercase. Do NOT reply with anything else.\"),\n",
    "    (\"human\", \"{question}\"),\n",
    "])\n",
    "\n",
    "prompt = template.format_messages(\n",
    "    max_items=10,\n",
    "    question=\"What are the planets?\",\n",
    ")\n",
    "\n",
    "result = chat.predict_messages(prompt)\n",
    "\n",
    "p = CommaOutputParser()\n",
    "\n",
    "p.parse(result.content) # ['mercury', 'venus', 'earth', 'mars', 'jupiter', 'saturn', 'uranus', 'neptune', 'pluto']\n",
    "\n",
    "chain = template | chat | CommaOutputParser() # | 로 chain 형성!\n",
    "\n",
    "chain.invoke({\n",
    "    \"max_items\":5,\n",
    "    \"question\": \"What are the pokemons?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's great! Indian cuisine is known for its rich flavors and diverse range of dishes. Here's a simple recipe for you to try:\n",
      "\n",
      "Butter Chicken (Murgh Makhani):\n",
      "Ingredients:\n",
      "- 500g boneless chicken, cut into pieces\n",
      "- 2 tablespoons butter\n",
      "- 1 onion, finely chopped\n",
      "- 2 teaspoons ginger-garlic paste\n",
      "- 2 teaspoons red chili powder\n",
      "- 1 teaspoon turmeric powder\n",
      "- 1 teaspoon garam masala\n",
      "- 1 cup tomato puree\n",
      "- 1/2 cup heavy cream\n",
      "- Salt to taste\n",
      "- Fresh coriander leaves for garnish\n",
      "\n",
      "Instructions:\n",
      "1. Heat butter in a pan over medium heat. Add the chopped onions and sauté until golden brown.\n",
      "2. Add ginger-garlic paste and sauté for another minute.\n",
      "3. Add red chili powder, turmeric powder, and garam masala. Mix well and cook for a minute.\n",
      "4. Add tomato puree and cook for 5-7 minutes until the oil separates from the mixture.\n",
      "5. Add the chicken pieces and cook until they are cooked through and tender.\n",
      "6. Stir in the heavy cream and season with salt. Simmer for another 5 minutes.\n",
      "7. Garnish with fresh coriander leaves and serve hot with naan bread or steamed rice.\n",
      "\n",
      "Remember, Indian cuisine offers a wide variety of dishes, so feel free to explore and experiment with different recipes and flavors. Enjoy your cooking!Butter Chicken, also known as Murgh Makhani, is a popular Indian dish that is traditionally made with chicken. However, as a vegetarian chef, I can suggest a delicious alternative to replace the chicken in this recipe.\n",
      "\n",
      "Instead of using chicken, you can use paneer, which is a type of Indian cheese. Paneer has a mild and creamy flavor that works well in rich and flavorful dishes like Butter Chicken. Here's how you can modify the recipe:\n",
      "\n",
      "Ingredients:\n",
      "- 500g paneer, cut into cubes\n",
      "- 2 tablespoons butter\n",
      "- 1 onion, finely chopped\n",
      "- 2 teaspoons ginger-garlic paste\n",
      "- 2 teaspoons red chili powder\n",
      "- 1 teaspoon turmeric powder\n",
      "- 1 teaspoon garam masala\n",
      "- 1 cup tomato puree\n",
      "- 1/2 cup heavy cream\n",
      "- Salt to taste\n",
      "- Fresh coriander leaves for garnish\n",
      "\n",
      "Instructions:\n",
      "1. Heat butter in a pan over medium heat. Add the chopped onions and sauté until golden brown.\n",
      "2. Add ginger-garlic paste and sauté for another minute.\n",
      "3. Add red chili powder, turmeric powder, and garam masala. Mix well and cook for a minute.\n",
      "4. Add tomato puree and cook for 5-7 minutes until the oil separates from the mixture.\n",
      "5. Add the paneer cubes and cook until they are heated through.\n",
      "6. Stir in the heavy cream and season with salt. Simmer for another 5 minutes.\n",
      "7. Garnish with fresh coriander leaves and serve hot with naan bread or steamed rice.\n",
      "\n",
      "By using paneer instead of chicken, you can still enjoy the rich and creamy flavors of Butter Chicken while keeping it vegetarian."
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content=\"Butter Chicken, also known as Murgh Makhani, is a popular Indian dish that is traditionally made with chicken. However, as a vegetarian chef, I can suggest a delicious alternative to replace the chicken in this recipe.\\n\\nInstead of using chicken, you can use paneer, which is a type of Indian cheese. Paneer has a mild and creamy flavor that works well in rich and flavorful dishes like Butter Chicken. Here's how you can modify the recipe:\\n\\nIngredients:\\n- 500g paneer, cut into cubes\\n- 2 tablespoons butter\\n- 1 onion, finely chopped\\n- 2 teaspoons ginger-garlic paste\\n- 2 teaspoons red chili powder\\n- 1 teaspoon turmeric powder\\n- 1 teaspoon garam masala\\n- 1 cup tomato puree\\n- 1/2 cup heavy cream\\n- Salt to taste\\n- Fresh coriander leaves for garnish\\n\\nInstructions:\\n1. Heat butter in a pan over medium heat. Add the chopped onions and sauté until golden brown.\\n2. Add ginger-garlic paste and sauté for another minute.\\n3. Add red chili powder, turmeric powder, and garam masala. Mix well and cook for a minute.\\n4. Add tomato puree and cook for 5-7 minutes until the oil separates from the mixture.\\n5. Add the paneer cubes and cook until they are heated through.\\n6. Stir in the heavy cream and season with salt. Simmer for another 5 minutes.\\n7. Garnish with fresh coriander leaves and serve hot with naan bread or steamed rice.\\n\\nBy using paneer instead of chicken, you can still enjoy the rich and creamy flavors of Butter Chicken while keeping it vegetarian.\")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.4 Chaining Chains\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI, ChatAnthropic\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "openai_api_key = os.environ.get('OPENAI_API_KEY')\n",
    "\n",
    "chat = ChatOpenAI(openai_api_key=openai_api_key, \n",
    "                  temperature=0.1, \n",
    "                  streaming=True, \n",
    "                  callbacks=[StreamingStdOutCallbackHandler()])\n",
    "chef_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"), \n",
    "    (\"human\", \"I want to cook {cuisine} food.\"),\n",
    "])\n",
    "\n",
    "chef_chain = chef_prompt | chat\n",
    "\n",
    "veg_chef_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a vegetarian chef specialized on making traditional recipies vegetarian. You find alternative ingredients and explain their preparation. You don't radically modify the recipe. If there is no alternative for a food just say you don't know how to replace it.\"), \n",
    "    (\"human\", \"{recipe}\"),\n",
    "])\n",
    "\n",
    "veg_chain = veg_chef_prompt | chat\n",
    "\n",
    "final_chain = {\"recipe\": chef_chain} | veg_chain # Runnable map\n",
    "\n",
    "final_chain.invoke({\n",
    "    \"cuisine\": \"indian\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: \n",
      "I know this:\n",
      "Capital: Berlin\n",
      "Language: German\n",
      "Food: Bratwurst and Sauerkraut\n",
      "Currency: Euro"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='AI: \\nI know this:\\nCapital: Berlin\\nLanguage: German\\nFood: Bratwurst and Sauerkraut\\nCurrency: Euro')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4.1 FewShotPromptTemplate\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI, ChatAnthropic\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.schema import BaseOutputParser\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "openai_api_key = os.environ.get('OPENAI_API_KEY')\n",
    "\n",
    "chat = ChatOpenAI(openai_api_key=openai_api_key, \n",
    "                  temperature=0.1, \n",
    "                  streaming=True, \n",
    "                  callbacks=[StreamingStdOutCallbackHandler()])\n",
    "\n",
    "examples = [\n",
    "    {\"question\": \"What do you know about France?\", \n",
    "             \"answer\": \"\"\"\n",
    "             Here is what I know: \n",
    "             Capital: Paris \n",
    "             Language: French \n",
    "             Food: Wine and Cheese \n",
    "             Currency: Euro\n",
    "             \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Italy?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Rome\n",
    "        Language: Italian\n",
    "        Food: Pizza and Pasta\n",
    "        Currency: Euro\n",
    "            \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Greece?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Athens\n",
    "        Language: Greek\n",
    "        Food: Souvlaki and Feta Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\"\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "example_template = \"\"\"\n",
    "    Human: {question}\n",
    "    AI: {answer}\n",
    "\"\"\"\n",
    "\n",
    "example_prompt = PromptTemplate.from_template(example_template)\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    "    suffix=\"Human: What do you know about {country}?\",\n",
    "    input_variables=[\"country\"]\n",
    ")\n",
    "\n",
    "prompt.format(country=\"Germany\")\n",
    "\n",
    "chain = prompt | chat\n",
    "\n",
    "chain.invoke({\n",
    "    \"country\": \"Germany\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        I know this:\n",
      "        Capital: Bangkok\n",
      "        Language: Thai\n",
      "        Food: Pad Thai and Tom Yum Soup\n",
      "        Currency: Thai Baht\n",
      "        "
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='\\n        I know this:\\n        Capital: Bangkok\\n        Language: Thai\\n        Food: Pad Thai and Tom Yum Soup\\n        Currency: Thai Baht\\n        ')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4.2 FewShotChatMessagePromptTemplate\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.few_shot import FewShotChatMessagePromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import ChatMessagePromptTemplate, ChatPromptTemplate\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "openai_api_key = os.environ.get('OPENAI_API_KEY')\n",
    "\n",
    "chat = ChatOpenAI(openai_api_key=openai_api_key, \n",
    "                  temperature=0.1, \n",
    "                  streaming=True, \n",
    "                  callbacks=[StreamingStdOutCallbackHandler()])\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"country\": \"France\",\n",
    "        \"answer\": \"\"\"\n",
    "        Here is what I know:\n",
    "        Capital: Paris\n",
    "        Language: French\n",
    "        Food: Wine and Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"country\": \"Italy\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Rome\n",
    "        Language: Italian\n",
    "        Food: Pizza and Pasta\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"country\": \"Greece\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Athens\n",
    "        Language: Greek\n",
    "        Food: Souvlaki and Feta Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"What do you know about {country}?\"),\n",
    "        (\"ai\", \"{answer}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "example_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a geography expert, you give short answers.\"),\n",
    "        example_prompt,\n",
    "        (\"human\", \"What do you know about {country}?\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = final_prompt | chat\n",
    "\n",
    "chain.invoke({\"country\": \"Thailand\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: What do you know about Italy?\\nAI:\\n        I know this:\\n        Capital: Rome\\n        Language: Italian\\n        Food: Pizza and Pasta\\n        Currency: Euro\\n        \\n\\nHuman: What do you know about Brazil?'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4.3 LengthBasedExampleSelector\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import example_selector\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.prompts.example_selector.base import BaseExampleSelector\n",
    "\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "openai_api_key = os.environ.get('OPENAI_API_KEY')\n",
    "\n",
    "chat = ChatOpenAI(openai_api_key=openai_api_key, \n",
    "                  temperature=0.1, \n",
    "                  streaming=True, \n",
    "                  callbacks=[StreamingStdOutCallbackHandler()])\n",
    "\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"question\": \"What do you know about France?\",\n",
    "        \"answer\": \"\"\"\n",
    "        Here is what I know:\n",
    "        Capital: Paris\n",
    "        Language: French\n",
    "        Food: Wine and Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Italy?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Rome\n",
    "        Language: Italian\n",
    "        Food: Pizza and Pasta\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Greece?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Athens\n",
    "        Language: Greek\n",
    "        Food: Souvlaki and Feta Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "class RandomExampleSelector(BaseExampleSelector):\n",
    "    def __init__(self, examples):\n",
    "        self.examples = examples\n",
    "\n",
    "    def add_example(self, example):\n",
    "        self.examples.append(example)\n",
    "\n",
    "    def select_examples(self, input_variables):\n",
    "        from random import choice\n",
    "\n",
    "        return [choice(self.examples)]\n",
    "\n",
    "\n",
    "example_prompt = PromptTemplate.from_template(\"Human: {question}\\nAI:{answer}\")\n",
    "\n",
    "example_selector = RandomExampleSelector(\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    example_selector=example_selector,\n",
    "    suffix=\"Human: What do you know about {country}?\",\n",
    "    input_variables=[\"country\"],\n",
    ")\n",
    "\n",
    "prompt.format(country=\"Brazil\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arrrrg! Me favorite food be a good ol' plate o' fish and chips! The salty sea air makes me crave the taste of fresh fish, battered and fried to perfection. And don't forget the crispy golden chips to go along with it! It be a meal fit for a pirate like meself! Arg arg!"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content=\"Arrrrg! Me favorite food be a good ol' plate o' fish and chips! The salty sea air makes me crave the taste of fresh fish, battered and fried to perfection. And don't forget the crispy golden chips to go along with it! It be a meal fit for a pirate like meself! Arg arg!\")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4.4 Serialization and Composiotion\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts.pipeline import PipelinePromptTemplate\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "openai_api_key = os.environ.get('OPENAI_API_KEY')\n",
    "\n",
    "chat = ChatOpenAI(openai_api_key=openai_api_key, \n",
    "                  temperature=0.1, \n",
    "                  streaming=True, \n",
    "                  callbacks=[StreamingStdOutCallbackHandler()])\n",
    "\n",
    "intro = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are a role playing assistant.\n",
    "    And you are impersonating a {character}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "example = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    This is an example of how you talk:\n",
    "\n",
    "    Human: {example_question}\n",
    "    You: {example_answer}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "start = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Start now!\n",
    "\n",
    "    Human: {question}\n",
    "    You:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "final = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    {intro}\n",
    "                                     \n",
    "    {example}\n",
    "                              \n",
    "    {start}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "prompts = [\n",
    "    (\"intro\", intro),\n",
    "    (\"example\", example),\n",
    "    (\"start\", start),\n",
    "]\n",
    "\n",
    "\n",
    "full_prompt = PipelinePromptTemplate(\n",
    "    final_prompt=final,\n",
    "    pipeline_prompts=prompts,\n",
    ")\n",
    "\n",
    "\n",
    "chain = full_prompt | chat\n",
    "\n",
    "chain.invoke(\n",
    "    {\n",
    "        \"character\": \"Pirate\",\n",
    "        \"example_question\": \"What is your location?\",\n",
    "        \"example_answer\": \"Arrrrg! That is a secret!! Arg arg!!\",\n",
    "        \"question\": \"What is your fav food?\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: How do you make italian pasta\"\n",
      "  ]\n",
      "}\n",
      "To make Italian pasta, you will need the following ingredients:\n",
      "\n",
      "- 2 cups of all-purpose flour\n",
      "- 2 large eggs\n",
      "- 1/2 teaspoon of salt\n",
      "- Water (if needed)\n",
      "\n",
      "Here's a step-by-step guide to making Italian pasta:\n",
      "\n",
      "1. On a clean surface or in a large mixing bowl, pour the flour and create a well in the center.\n",
      "2. Crack the eggs into the well and add the salt.\n",
      "3. Using a fork, beat the eggs and gradually incorporate the flour from the sides of the well. Continue mixing until a dough starts to form.\n",
      "4. Once the dough becomes too stiff to mix with a fork, use your hands to knead it. If the dough is too dry, add a little water, one tablespoon at a time, until it comes together. If it's too sticky, add a little flour.\n",
      "5. Knead the dough for about 5-10 minutes until it becomes smooth and elastic.\n",
      "6. Shape the dough into a ball and cover it with a clean kitchen towel. Let it rest for at least 30 minutes to allow the gluten to relax.\n",
      "7. After resting, divide the dough into smaller portions. Flatten each portion with a rolling pin or a pasta machine until it reaches the desired thickness. You can make it as thin or thick as you prefer.\n",
      "8. Once the dough is rolled out, you can cut it into various pasta shapes like fettuccine, spaghetti, or lasagna sheets.\n",
      "9. If making long pasta like spaghetti or fettuccine, dust the dough with flour and roll it up loosely. Use a sharp knife to cut it into thin strips.\n",
      "10. If making lasagna sheets, cut the rolled-out dough into rectangular pieces of the desired size.\n",
      "11. Once the pasta is cut, you can cook it immediately in boiling salted water for about 2-5 minutes until al dente. Alternatively, you can let it dry for a few hours or overnight before cooking.\n",
      "12. Serve the cooked pasta with your favorite sauce, such as marinara, carbonara, or pesto.\n",
      "\n",
      "Enjoy your homemade Italian pasta!\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:llm:ChatOpenAI] [25.83s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"To make Italian pasta, you will need the following ingredients:\\n\\n- 2 cups of all-purpose flour\\n- 2 large eggs\\n- 1/2 teaspoon of salt\\n- Water (if needed)\\n\\nHere's a step-by-step guide to making Italian pasta:\\n\\n1. On a clean surface or in a large mixing bowl, pour the flour and create a well in the center.\\n2. Crack the eggs into the well and add the salt.\\n3. Using a fork, beat the eggs and gradually incorporate the flour from the sides of the well. Continue mixing until a dough starts to form.\\n4. Once the dough becomes too stiff to mix with a fork, use your hands to knead it. If the dough is too dry, add a little water, one tablespoon at a time, until it comes together. If it's too sticky, add a little flour.\\n5. Knead the dough for about 5-10 minutes until it becomes smooth and elastic.\\n6. Shape the dough into a ball and cover it with a clean kitchen towel. Let it rest for at least 30 minutes to allow the gluten to relax.\\n7. After resting, divide the dough into smaller portions. Flatten each portion with a rolling pin or a pasta machine until it reaches the desired thickness. You can make it as thin or thick as you prefer.\\n8. Once the dough is rolled out, you can cut it into various pasta shapes like fettuccine, spaghetti, or lasagna sheets.\\n9. If making long pasta like spaghetti or fettuccine, dust the dough with flour and roll it up loosely. Use a sharp knife to cut it into thin strips.\\n10. If making lasagna sheets, cut the rolled-out dough into rectangular pieces of the desired size.\\n11. Once the pasta is cut, you can cook it immediately in boiling salted water for about 2-5 minutes until al dente. Alternatively, you can let it dry for a few hours or overnight before cooking.\\n12. Serve the cooked pasta with your favorite sauce, such as marinara, carbonara, or pesto.\\n\\nEnjoy your homemade Italian pasta!\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        },\n",
      "        \"type\": \"ChatGenerationChunk\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessageChunk\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"example\": false,\n",
      "            \"content\": \"To make Italian pasta, you will need the following ingredients:\\n\\n- 2 cups of all-purpose flour\\n- 2 large eggs\\n- 1/2 teaspoon of salt\\n- Water (if needed)\\n\\nHere's a step-by-step guide to making Italian pasta:\\n\\n1. On a clean surface or in a large mixing bowl, pour the flour and create a well in the center.\\n2. Crack the eggs into the well and add the salt.\\n3. Using a fork, beat the eggs and gradually incorporate the flour from the sides of the well. Continue mixing until a dough starts to form.\\n4. Once the dough becomes too stiff to mix with a fork, use your hands to knead it. If the dough is too dry, add a little water, one tablespoon at a time, until it comes together. If it's too sticky, add a little flour.\\n5. Knead the dough for about 5-10 minutes until it becomes smooth and elastic.\\n6. Shape the dough into a ball and cover it with a clean kitchen towel. Let it rest for at least 30 minutes to allow the gluten to relax.\\n7. After resting, divide the dough into smaller portions. Flatten each portion with a rolling pin or a pasta machine until it reaches the desired thickness. You can make it as thin or thick as you prefer.\\n8. Once the dough is rolled out, you can cut it into various pasta shapes like fettuccine, spaghetti, or lasagna sheets.\\n9. If making long pasta like spaghetti or fettuccine, dust the dough with flour and roll it up loosely. Use a sharp knife to cut it into thin strips.\\n10. If making lasagna sheets, cut the rolled-out dough into rectangular pieces of the desired size.\\n11. Once the pasta is cut, you can cook it immediately in boiling salted water for about 2-5 minutes until al dente. Alternatively, you can let it dry for a few hours or overnight before cooking.\\n12. Serve the cooked pasta with your favorite sauce, such as marinara, carbonara, or pesto.\\n\\nEnjoy your homemade Italian pasta!\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"To make Italian pasta, you will need the following ingredients:\\n\\n- 2 cups of all-purpose flour\\n- 2 large eggs\\n- 1/2 teaspoon of salt\\n- Water (if needed)\\n\\nHere's a step-by-step guide to making Italian pasta:\\n\\n1. On a clean surface or in a large mixing bowl, pour the flour and create a well in the center.\\n2. Crack the eggs into the well and add the salt.\\n3. Using a fork, beat the eggs and gradually incorporate the flour from the sides of the well. Continue mixing until a dough starts to form.\\n4. Once the dough becomes too stiff to mix with a fork, use your hands to knead it. If the dough is too dry, add a little water, one tablespoon at a time, until it comes together. If it's too sticky, add a little flour.\\n5. Knead the dough for about 5-10 minutes until it becomes smooth and elastic.\\n6. Shape the dough into a ball and cover it with a clean kitchen towel. Let it rest for at least 30 minutes to allow the gluten to relax.\\n7. After resting, divide the dough into smaller portions. Flatten each portion with a rolling pin or a pasta machine until it reaches the desired thickness. You can make it as thin or thick as you prefer.\\n8. Once the dough is rolled out, you can cut it into various pasta shapes like fettuccine, spaghetti, or lasagna sheets.\\n9. If making long pasta like spaghetti or fettuccine, dust the dough with flour and roll it up loosely. Use a sharp knife to cut it into thin strips.\\n10. If making lasagna sheets, cut the rolled-out dough into rectangular pieces of the desired size.\\n11. Once the pasta is cut, you can cook it immediately in boiling salted water for about 2-5 minutes until al dente. Alternatively, you can let it dry for a few hours or overnight before cooking.\\n12. Serve the cooked pasta with your favorite sauce, such as marinara, carbonara, or pesto.\\n\\nEnjoy your homemade Italian pasta!\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4.5 Caching\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.globals import set_llm_cache, set_debug\n",
    "from langchain.cache import InMemoryCache, SQLiteCache\n",
    "\n",
    "set_llm_cache(InMemoryCache())\n",
    "set_debug(True)\n",
    "\n",
    "set_llm_cache(SQLiteCache(\"cache.db\"))\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "openai_api_key = os.environ.get('OPENAI_API_KEY')\n",
    "\n",
    "chat = ChatOpenAI(openai_api_key=openai_api_key, \n",
    "                  temperature=0.1, \n",
    "                  streaming=True, \n",
    "                  callbacks=[StreamingStdOutCallbackHandler()])\n",
    "\n",
    "chat.predict(\"How do you make italian pasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a simple recipe for making soju at home:\n",
      "\n",
      "Ingredients:\n",
      "- 1 cup of rice\n",
      "- 1 cup of nuruk (Korean fermentation starter)\n",
      "- 8 cups of water\n",
      "- 1 tablespoon of yeast\n",
      "- 1 cup of sugar (optional, for sweetening)\n",
      "\n",
      "Instructions:\n",
      "1. Rinse the rice thoroughly until the water runs clear.\n",
      "2. Soak the rice in water for about 1 hour, then drain.\n",
      "3. Steam the rice until it becomes soft and fully cooked.\n",
      "4. Let the cooked rice cool down to room temperature.\n",
      "5. In a large container, combine the cooled rice, nuruk, and water. Mix well.\n",
      "6. Cover the container with a clean cloth and let it ferment for about 7-10 days at room temperature.\n",
      "7. After the fermentation period, strain the mixture to remove any solids.\n",
      "8. Dissolve the yeast in a small amount of warm water and add it to the strained liquid.\n",
      "9. Cover the container again and let it ferment for an additional 2-3 days.\n",
      "10. After the second fermentation, strain the liquid again to remove any remaining solids.\n",
      "11. At this point, you can add sugar if you prefer a sweeter taste. Stir until the sugar is fully dissolved.\n",
      "12. Transfer the soju into clean bottles or jars and refrigerate for a few hours before serving.\n",
      "13. Soju is typically enjoyed chilled, either straight or mixed with other beverages or fruit juices.\n",
      "\n",
      "Please note that making soju at home may not produce the same flavor and alcohol content as commercially produced soju.Here is a basic recipe for making bread:\n",
      "\n",
      "Ingredients:\n",
      "- 4 cups all-purpose flour\n",
      "- 2 teaspoons active dry yeast\n",
      "- 2 teaspoons salt\n",
      "- 2 tablespoons sugar\n",
      "- 2 tablespoons vegetable oil\n",
      "- 1 ½ cups warm water (around 110°F/43°C)\n",
      "\n",
      "Instructions:\n",
      "1. In a large mixing bowl, combine the warm water and sugar. Stir until the sugar is dissolved.\n",
      "2. Sprinkle the yeast over the water and let it sit for about 5 minutes until it becomes foamy.\n",
      "3. Add the flour, salt, and vegetable oil to the bowl. Mix everything together until a dough forms.\n",
      "4. Transfer the dough onto a floured surface and knead it for about 10 minutes until it becomes smooth and elastic. You can also use a stand mixer with a dough hook attachment for this step.\n",
      "5. Place the dough in a greased bowl and cover it with a clean kitchen towel. Let it rise in a warm place for about 1-2 hours or until it doubles in size.\n",
      "6. Once the dough has risen, punch it down to release any air bubbles. Shape it into a loaf by rolling it tightly and tucking the ends underneath.\n",
      "7. Place the shaped dough into a greased loaf pan and cover it again with the kitchen towel. Let it rise for another 30-45 minutes.\n",
      "8. Preheat your oven to 375°F (190°C).\n",
      "9. Bake the bread in the preheated oven for about 30-35 minutes or until it turns golden brown and sounds hollow when tapped on the bottom.\n",
      "10. Remove the bread from the oven and let it cool in the pan for a few minutes. Then transfer it to a wire rack to cool completely before slicing.\n",
      "\n",
      "Note: This is a basic bread recipe, and you can customize it by adding ingredients like herbs, cheese, or seeds to the dough for different flavors.Here is a simple recipe for making soju at home:\n",
      "\n",
      "Ingredients:\n",
      "- 1 cup of rice\n",
      "- 1 cup of nuruk (Korean fermentation starter)\n",
      "- 8 cups of water\n",
      "- 1 tablespoon of yeast\n",
      "- 1 cup of sugar (optional, for sweetening)\n",
      "\n",
      "Instructions:\n",
      "1. Rinse the rice thoroughly until the water runs clear.\n",
      "2. Soak the rice in water for about 1 hour, then drain.\n",
      "3. Steam the rice until it becomes soft and fully cooked.\n",
      "4. Let the cooked rice cool down to room temperature.\n",
      "5. In a large container, combine the cooled rice, nuruk, and water. Mix well.\n",
      "6. Cover the container with a clean cloth and let it ferment for about 7-10 days at room temperature.\n",
      "7. After the fermentation period, strain the mixture to remove any solids.\n",
      "8. Dissolve the yeast in a small amount of warm water and add it to the strained liquid.\n",
      "9. Cover the container again and let it ferment for an additional 2-3 days.\n",
      "10. After the second fermentation, strain the liquid again to remove any remaining solids.\n",
      "11. At this point, you can add sugar if you prefer a sweeter taste. Stir until the sugar is fully dissolved.\n",
      "12. Transfer the soju into clean bottles or jars and refrigerate for a few hours before serving.\n",
      "13. Soju is typically enjoyed chilled, either straight or mixed with other beverages or fruit juices.\n",
      "\n",
      "Please note that making soju at home may not produce the same flavor and alcohol content as commercially produced soju. Here is a basic recipe for making bread:\n",
      "\n",
      "Ingredients:\n",
      "- 4 cups all-purpose flour\n",
      "- 2 teaspoons active dry yeast\n",
      "- 2 teaspoons salt\n",
      "- 2 tablespoons sugar\n",
      "- 2 tablespoons vegetable oil\n",
      "- 1 ½ cups warm water (around 110°F/43°C)\n",
      "\n",
      "Instructions:\n",
      "1. In a large mixing bowl, combine the warm water and sugar. Stir until the sugar is dissolved.\n",
      "2. Sprinkle the yeast over the water and let it sit for about 5 minutes until it becomes foamy.\n",
      "3. Add the flour, salt, and vegetable oil to the bowl. Mix everything together until a dough forms.\n",
      "4. Transfer the dough onto a floured surface and knead it for about 10 minutes until it becomes smooth and elastic. You can also use a stand mixer with a dough hook attachment for this step.\n",
      "5. Place the dough in a greased bowl and cover it with a clean kitchen towel. Let it rise in a warm place for about 1-2 hours or until it doubles in size.\n",
      "6. Once the dough has risen, punch it down to release any air bubbles. Shape it into a loaf by rolling it tightly and tucking the ends underneath.\n",
      "7. Place the shaped dough into a greased loaf pan and cover it again with the kitchen towel. Let it rise for another 30-45 minutes.\n",
      "8. Preheat your oven to 375°F (190°C).\n",
      "9. Bake the bread in the preheated oven for about 30-35 minutes or until it turns golden brown and sounds hollow when tapped on the bottom.\n",
      "10. Remove the bread from the oven and let it cool in the pan for a few minutes. Then transfer it to a wire rack to cool completely before slicing.\n",
      "\n",
      "Note: This is a basic bread recipe, and you can customize it by adding ingredients like herbs, cheese, or seeds to the dough for different flavors. \n",
      "\n",
      "Tokens Used: 0\n",
      "\tPrompt Tokens: 0\n",
      "\tCompletion Tokens: 0\n",
      "Successful Requests: 0\n",
      "Total Cost (USD): $0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rlagusrb/miniconda3/envs/FullStack-GPT/lib/python3.11/site-packages/langchain/llms/openai.py:216: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "/home/rlagusrb/miniconda3/envs/FullStack-GPT/lib/python3.11/site-packages/langchain/llms/openai.py:811: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 4.6 Serialization\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain.llms.openai import OpenAI\n",
    "from langchain.llms.loading import load_llm\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "openai_api_key = os.environ.get('OPENAI_API_KEY')\n",
    "\n",
    "chat = ChatOpenAI(openai_api_key=openai_api_key, \n",
    "                  temperature=0.1, \n",
    "                  streaming=True, \n",
    "                  callbacks=[StreamingStdOutCallbackHandler()])\n",
    "\n",
    "\n",
    "with get_openai_callback() as usage:\n",
    "    a = chat.predict(\"What is the recipe for soju\")\n",
    "    b = chat.predict(\"What is the recipe for bread\")\n",
    "    print(a, b, \"\\n\")\n",
    "    print(usage)\n",
    "\n",
    "chat2 = OpenAI(openai_api_key=openai_api_key, \n",
    "               temperature=0.1, \n",
    "               max_tokens=450, \n",
    "               model=\"gpt-3.5-turbo-16k\")\n",
    "\n",
    "chat2.save(\"model.json\")\n",
    "\n",
    "chat3 = load_llm(\"model.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='Hi!'), AIMessage(content='How are you?')]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5.0 Conversation Buffer Memory\n",
    "\n",
    "from operator import itemgetter\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.schema.runnable import RunnablePassthrough, RunnableLambda\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "openai_api_key = os.environ.get('OPENAI_API_KEY')\n",
    "\n",
    "model = ChatOpenAI(openai_api_key=openai_api_key)\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "memory.save_context({\"input\": \"Hi!\"}, {\"output\": \"How are you?\"})\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='2'),\n",
       "  AIMessage(content='2'),\n",
       "  HumanMessage(content='3'),\n",
       "  AIMessage(content='3'),\n",
       "  HumanMessage(content='4'),\n",
       "  AIMessage(content='4'),\n",
       "  HumanMessage(content='5'),\n",
       "  AIMessage(content='5')]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5.1 Conversation Buffer Window Memory\n",
    "\n",
    "from operator import itemgetter\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.schema.runnable import RunnablePassthrough, RunnableLambda\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "openai_api_key = os.environ.get('OPENAI_API_KEY')\n",
    "\n",
    "memory = ConversationBufferWindowMemory(\n",
    "    return_messages=True,\n",
    "    k=4\n",
    ")\n",
    "\n",
    "def add_message(input, output):\n",
    "    memory.save_context({\"inputs\": input}, {\"output\": output})\n",
    "\n",
    "add_message(1, 1)\n",
    "add_message(2, 2)\n",
    "add_message(3, 3)\n",
    "add_message(4, 4)\n",
    "add_message(5, 5) # 1번 메시지는 삭제!\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.2 Conversation Summary Memory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationSummaryMemory\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "openai_api_key = os.environ.get('OPENAI_API_KEY')\n",
    "\n",
    "llm = ChatOpenAI(openai_api_key=openai_api_key, temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryMemory(llm=llm)\n",
    "\n",
    "def add_message(input, output):\n",
    "    memory.save_context({\"inputs\": input}, {\"output\": output})\n",
    "\n",
    "def get_history():\n",
    "    return memory.load_memory_variables({})\n",
    "\n",
    "add_message(\"Hi I'm Nicolas, I live in South Korea\", \"Wow that is so cool!\")\n",
    "add_message(\"South Korea is so pretty\", \"I wish I could go!!!\")\n",
    "\n",
    "get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.3 Conversation Summary Buffer Memory\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "openai_api_key = os.environ.get('OPENAI_API_KEY')\n",
    "\n",
    "llm = ChatOpenAI(openai_api_key=openai_api_key, temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=150,\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "def add_message(input, output):\n",
    "    memory.save_context({\"inputs\": input}, {\"output\": output})\n",
    "\n",
    "def get_history():\n",
    "    return memory.load_memory_variables({})\n",
    "\n",
    "add_message(\"Hi I'm Nicolas, I live in South Korea\", \"Wow that is so cool!\")\n",
    "add_message(\"South Korea is so pretty\", \"I wish I could go!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.4 Conversation KG Memory\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationKGMemory\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "openai_api_key = os.environ.get('OPENAI_API_KEY')\n",
    "\n",
    "llm = ChatOpenAI(openai_api_key=openai_api_key, temperature=0.1)\n",
    "\n",
    "memory = ConversationKGMemory(\n",
    "    llm=llm,\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "def add_message(input, output):\n",
    "    memory.save_context({\"inputs\": input}, {\"output\": output})\n",
    "\n",
    "add_message(\"Hi I'm Nicolas, I live in South Korea\", \"Wow that is so cool!\")\n",
    "memory.load_memory_variables({\"input\": \"who is Nicolas\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    You are a helpful AI talking to a human.\n",
      "\n",
      "    \n",
      "    Human:My name is Nico\n",
      "    You:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    You are a helpful AI talking to a human.\n",
      "\n",
      "    Human: My name is Nico\n",
      "AI: Hello Nico! How can I assist you today?\n",
      "    Human:I live in Seoul\n",
      "    You:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "    You are a helpful AI talking to a human.\n",
      "\n",
      "    Human: My name is Nico\n",
      "AI: Hello Nico! How can I assist you today?\n",
      "Human: I live in Seoul\n",
      "AI: That's great! Seoul is a vibrant and bustling city. How can I assist you today, Nico?\n",
      "    Human:What is my name?\n",
      "    You:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Your name is Nico.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5.5 Memory on LLMChain\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "openai_api_key = os.environ.get('OPENAI_API_KEY')\n",
    "\n",
    "llm = ChatOpenAI(openai_api_key=openai_api_key, temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=120,\n",
    "    memory_key=\"chat_history\",\n",
    ")\n",
    "\n",
    "template = \"\"\"\n",
    "    You are a helpful AI talking to a human.\n",
    "\n",
    "    {chat_history}\n",
    "    Human:{question}\n",
    "    You:\n",
    "\"\"\"\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    prompt=PromptTemplate.from_template(template),\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "chain.predict(question=\"My name is Nico\")\n",
    "chain.predict(question=\"I live in Seoul\")\n",
    "chain.predict(question=\"What is my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a helpful AI talking to a human\n",
      "Human: My name is Nico\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello Nico! How can I assist you today?'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5.6 Chat Based Memory\n",
    "\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "openai_api_key = os.environ.get('OPENAI_API_KEY')\n",
    "\n",
    "llm = ChatOpenAI(openai_api_key=openai_api_key, temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=120,\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True,\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful AI talking to a human\"),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    memory=memory,\n",
    "    prompt=prompt,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "chain.predict(question=\"My name is Nico\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.7 LCEL Based Memory\n",
    "\n",
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "openai_api_key = os.environ.get('OPENAI_API_KEY')\n",
    "\n",
    "llm = ChatOpenAI(openai_api_key=openai_api_key, temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=120,\n",
    "    return_messages=True,\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful AI talking to a human\"),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def load_memory(_):\n",
    "    return memory.load_memory_variables({})[\"history\"]\n",
    "\n",
    "\n",
    "chain = RunnablePassthrough.assign(history=load_memory) | prompt | llm\n",
    "\n",
    "\n",
    "def invoke_chain(question):\n",
    "    result = chain.invoke({\"question\": question})\n",
    "    memory.save_context(\n",
    "        {\"input\": question},\n",
    "        {\"output\": result.content},\n",
    "    )\n",
    "    print(result)\n",
    "\n",
    "invoke_chain(\"My name is nico\")\n",
    "invoke_chain(\"What is my name?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FullStack-GPT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
